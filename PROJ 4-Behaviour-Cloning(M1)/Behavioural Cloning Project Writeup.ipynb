{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral Cloning Project Writeup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the Udacity Self Driving Car Nanodegree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Harry Turner on 21st March"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep convolutional neural networks offer improved performance over existing traditional robotic techniques when controlling an autonomous car. This project explores the application of deep networks to this problem, and describes the approach taken to develop such a network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach taken in this project is to start simply, and just get something working. From there, complexity is added in bit by bit to improve the performance. This is a useful way of approaching this task, since it isn’t clear from the outset what the solution should look like, beyond the fact that it should probably require a convolutional neural network. The approach is described in the order in which the activities were carried out, each separated into its own section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration of the Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in any project is to explore the dataset, in this case, the simulator. Once the simulator was working, I spent some time driving around the track, and made notes of what the neural network would have to deal with. For example, I noted areas where the tracks had no edges, places with sharp bends, and distracting features on the side of the road that may degrade the performance of the network. An example of a piece of track with no edges is shown below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![no-edge.png](writeup-images/no-edge.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After I’d spent some time exploring the simulator, I started collecting training data. I defer the discussion of how I chose what data to generate, to a later section dedicated to the training process, called <b>Training</b>. At this stage, it is sufficient to note that I generated the data using the record feature of the simulator, which saved images and steering angles to a folder on my local system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Something Working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once I had some training data, my first goal was to simply get something working. The main reason for this was to confirm that the environment was setup appropriately, and that my network was both able to learn from the data, and control the car (albeit badly). The first network architecture I used was a simple vanilla neural network, with one hidden layer with 50 neurons, built using the Keras framework running on top of Tensorflow. The inputs to the network are flattened and then pass through the network, with the output consisting of just one neuron. Note that no activation function was applied to the output. The Keras code to accomplish this is shown in the code block below, a visual depiction of the architecture is shown in the image below the code block. Note also that the input layer consists of a cropped image, which will be explained shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![vanilla-network.png](writeup-images/vanilla-network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network was quick to train, and when tested in the simulator the steering rapidly bounced back and forth, resulting in the car slowly juddering forward. Eventually, the car turned off the track and drove into the lake. This was what I expected, the network did a terrible job at controlling the car, but it proved that the setup worked, and that all I needed to do was improve the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![into-lake.png](writeup-images/into-lake.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next five sections discuss the improvements made to the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvements: Normalisation and Cropping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A clue to the first method for improving the network was given by observing the validation loss during training. The validation loss was huge! The reason for this is that the inputs to the network were raw pixel values, which ranged from 1 to 255, this meant that the output of the network was large, and the network had to spend a lot of time and effort bringing the weights down to improve the output. The network could avoid this step if I normalised the images before they were input to the network. This actually resulted in a faster training time too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I implemented normalisation using a Keras Lambda layer, where I scaled each pixel value down to between 0 and 1, and also centred each value about 0, so that the final pixel values ranged between -0.5 and 0.5. The code to achieve this is shown in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=(160,320,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also used a Keras crop layer to crop the input images to just the lower half. This is because the road is all the network really needs to navigate, the top half of the image is mostly unnecessary and distracting for the network. The code to accomplish this is shown in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Cropping2D(cropping=((70, 25), (0, 0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvements: Artificial Training Set Expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another simple technique that can greatly improve network performance is to use more training data by way of artificially expanding the dataset. For this project, I could have simply driven the car around the track a few more times, however in practice, obtaining more data can be costly. To expand the dataset, I flipped each image, and changed the sign of the steering angle. The effect of this was as if I had driven around the track the other way. The effect of this improvement was to increase training times, but to also improve the accuracy.\n",
    "\n",
    "This functionality is implemented in a dedicated data object, which is explained later, and can be found in the file <b>helper.py</b>. However, the short piece of code that actually performs the flipping is shown in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every image and measurement...\n",
    "for image, measurement in zip(images, measurements):\n",
    "    \n",
    "    # Append the original image, and a flipped image.\n",
    "    aug_images.append(image)\n",
    "    aug_images.append(cv.flip(image, 1))\n",
    "    \n",
    "    # Append the original measurement, and a flipped measurement.\n",
    "    aug_measurements.append(measurement)\n",
    "    aug_measurements.append(measurement*-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of a flipped image is shown below. It isn't obvious that the image is flipped, except by realising that the lake is on the wrong side!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![reversed.png](writeup-images/reversed.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvements: LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next improvement was to replace the simple network with a more sophisticated one. From my previous experience, I know that the LeNet architecture offers sophistication, whilst not being too large which would increase training times dramatically. I therefore implemented the LeNet architecture with the input layer consisting of a three channel input image, and the final output layer consisting of only one neuron, rather than the usual ten. I also removed the softmax layer. The Keras code to implement this network is shown in the code block. A visual depiction of the architecture is shown in the image below the code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(6, (5, 5), activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Convolution2D(6, (5, 5), activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120))\n",
    "model.add(Dense(84))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![lenet-network.png](writeup-images/lenet-network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of implementing this network was to dramatically improve the performance of the car. Although training times were increased to about 10 minutes per epoch, the final network was able to navigate the car all the way to the bridge before turning off the road and ending up in the lake again. This was a substantial improvement and suggested that increasing the sophistication of the network still further may improve the performance even more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvements: NVIDIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the LeNet architecture over the vanilla one layer network substantially increased the performance. To see if I could get even more performance, I used a very sophisticated network from NVIDIA, which has been used to control self-driving cars in the real world. This network is much larger, with five convolutional layers and three fully connected layers. This gives the network much more powerful decision making capability, which may allow the car to navigate the track completely. The cost of using such a network is that the training times are increased again, and the network could badly over fit, therefore I added dropout to the last two convolutional layers. The Keras code to implement this network is shown in the code block below. A depiction of the architecture is shown in the image below the code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(24, (5, 5), activation=\"relu\", strides=(2,2)))\n",
    "model.add(Conv2D(36, (5, 5), activation=\"relu\", strides=(2,2)))\n",
    "model.add(Conv2D(48, (5, 5), activation=\"relu\", strides=(2,2)))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nvidia-network.png](writeup-images/nvidia-network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After implementing this architecture, the car’s performance was sufficient to allow it to reach the bridge and cross it; however during a tight turn after the bridge, with no edges on the road, the car ran off the road into the sand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![into-sand.png](writeup-images/into-sand.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, I was happy that my network was sophisticated enough to manage the track, but I realised that I needed some more training data targeted to this particular turn. Specifically, I needed to record data of the car about to run off the track, and steering sharply to get back on course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvements: Targeted Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final improvement that enabled my car to navigate the track completely was to record more training data in situations where the car was struggling to manoeuvre properly. In training mode, I drove the car up to the edge of the track in those difficult areas, and turned sharply to get back on course. I did this multiple times for each difficult area, and then augmented this new data by flipping the images. I then added this data to the training set and used this new set to train the NVIDIA architecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of using this new dataset was that the car learned to turn sharply when it approached the edge of the road in these difficult areas. When testing, the car reaches those parts of the track, and the network is able to steer the car enough to stay on the track. After this step, the car was able to navigate the entire track successfully.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final architecture has already been introduced, therefore only a summary is presented in this section. A visual depiction of the architecture is shown below, and a summary of the layers is shown below the image. The parts to note are that dropout has been applied to the last two convolutional layers, with a keep probability of 0.75. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nvidia-network.png](writeup-images/nvidia-network.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "lambda_1 (Lambda)            (None, 160, 320, 3)       0         \n",
    "_________________________________________________________________\n",
    "cropping2d_1 (Cropping2D)    (None, 65, 320, 3)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_1 (Conv2D)            (None, 31, 158, 24)       1824      \n",
    "_________________________________________________________________\n",
    "conv2d_2 (Conv2D)            (None, 14, 77, 36)        21636     \n",
    "_________________________________________________________________\n",
    "conv2d_3 (Conv2D)            (None, 5, 37, 48)         43248     \n",
    "_________________________________________________________________\n",
    "conv2d_4 (Conv2D)            (None, 3, 35, 64)         27712     \n",
    "_________________________________________________________________\n",
    "dropout_1 (Dropout)          (None, 3, 35, 64)         0         \n",
    "_________________________________________________________________\n",
    "conv2d_5 (Conv2D)            (None, 1, 33, 64)         36928     \n",
    "_________________________________________________________________\n",
    "dropout_2 (Dropout)          (None, 1, 33, 64)         0         \n",
    "_________________________________________________________________\n",
    "flatten_1 (Flatten)          (None, 2112)              0         \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 100)               211300    \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 50)                5050      \n",
    "_________________________________________________________________\n",
    "dense_3 (Dense)              (None, 10)                510       \n",
    "_________________________________________________________________\n",
    "dense_4 (Dense)              (None, 1)                 11        \n",
    "=================================================================\n",
    "Total params: 348,219\n",
    "Trainable params: 348,219\n",
    "Non-trainable params: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section briefly describes the approach to collecting data, and the characteristics of the final dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is managed using a custom object called a Data Object. This class is defined in a file called <b>helper.py</b>, and provides an easy and consistent interface for loading in datasets, augmenting them, and optionally using side camera images. Note that this class is designed for use with the Behavioural Cloning Udacity project, and isn’t generally applicable to other projects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of four sets, two for normal driving, and two for recovery driving. Both normal datasets are augmented, and use side camera images. The recovery driving datasets are only augmented. The code to load the relevant data sets is shown below in the code block. I've added functionality to print out which datasets are being used, for tracking purposes. An example of this output is shown in the output box below the code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_object.add_data(\"training_1\", augment=True, side_images=True)\n",
    "data_object.add_data(\"training_2\", augment=True, side_images=True)\n",
    "data_object.add_data(\"recovery_1\", augment=True, side_images=False)\n",
    "data_object.add_data(\"recovery_2\", augment=True, side_images=False)\n",
    "\n",
    "data_object.print_log()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using augmented training_1 data with side images. \n",
    "Using augmented training_2 data with side images. \n",
    "Using augmented recovery_1 data.\n",
    "Using augmented recovery_2 data.\n",
    "There are 36482 images in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset consists of data recorded for the car driving normally around the track, whilst staying in the centre of the lane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![center-lane.png](writeup-images/center-lane.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recovery Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset consists of the car making recovery manoeuvres. Specifically, the car is brought up to the edge of the track whilst the recorder is off. The recorder is then turned on, and the car is navigated back into the centre of the lane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A set of training data was collected that included both normal and recovery driving. A convolutional architecture based on a network proposed by NVIDIA is trained on the data, and dropout is applied to the last two convolution layers. The network is used to control the car in simulation, and the car navigates around the entire track without touching the sides of the road. Overall the car has performed well and meets specifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further improvements could be made by both using more training data, and training for longer. More tracks could be used to generalise the performance of the car."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
